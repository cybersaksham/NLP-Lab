{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self) -> None:\n",
    "        self.start = \"S\"\n",
    "        self.grammar = {}\n",
    "        self.terminals = []\n",
    "        self.nonTerminals = []\n",
    "\n",
    "    def inputGrammar(self):\n",
    "        grammar = {}\n",
    "        symbols = set()\n",
    "        n = int(input())\n",
    "        for i in range(n):\n",
    "            rule = input()\n",
    "            for token in rule.split():\n",
    "                symbols.add(token)\n",
    "            nt = rule.split()[0]\n",
    "            ter = rule.split()[1:]\n",
    "            if nt in grammar.keys():\n",
    "                grammar[nt].append(ter)\n",
    "            else:\n",
    "                grammar[nt] = [ter]\n",
    "        for token in list(symbols):\n",
    "            if token in grammar.keys():\n",
    "                self.nonTerminals.append(token)\n",
    "            else:\n",
    "                self.terminals.append(token)\n",
    "        self.grammar = grammar\n",
    "    \n",
    "    def printGrammar(self):\n",
    "        print(f\"Non Terminals: {' '.join(self.nonTerminals)}\")\n",
    "        print(f\"Terminals: {' '.join(self.terminals)}\")\n",
    "        for nt in self.grammar.keys():\n",
    "            for rule in self.grammar[nt]:\n",
    "                print(nt, end=\" -> \")\n",
    "                print(\" \".join(rule))\n",
    "    \n",
    "    def parse(self, sentence, lexicons):\n",
    "        tokens = sentence.split()\n",
    "        l = len(tokens)\n",
    "        state = [[\"S\"], 0]\n",
    "        backup = []\n",
    "        steps = 1\n",
    "        isBackup = False\n",
    "        while True:\n",
    "            if isBackup:\n",
    "                if len(backup) > 0:\n",
    "                    state = backup[0]\n",
    "                    backup.pop(0)\n",
    "                    isBackup = False\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Parsing Failed\")\n",
    "                    return False\n",
    "            if len(state[0]) == 0:\n",
    "                if state[1] < l:\n",
    "                    isBackup = True\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Parsing Done\")\n",
    "                    return True\n",
    "            tok = state[0][0]\n",
    "            ptr = state[1]\n",
    "            print(\"Step: \", steps)\n",
    "            print(\"State: \", state)\n",
    "            print(\"Backup: \", backup)\n",
    "            steps += 1\n",
    "            print()\n",
    "            if tok in self.nonTerminals:\n",
    "                rules = self.grammar[tok].copy()\n",
    "                if len(rules) > 1:\n",
    "                    for r in rules[1:]:\n",
    "                        r.extend(state[0][1:])\n",
    "                        backup.append([r, ptr])\n",
    "                r = rules[0].copy()\n",
    "                r.extend(state[0][1:])\n",
    "                state[0] = r.copy()\n",
    "            elif tok in self.terminals:\n",
    "                if ptr >= l:\n",
    "                    isBackup = True\n",
    "                    continue\n",
    "                w = tokens[ptr]\n",
    "                if tok not in lexicons[w]:\n",
    "                    isBackup = True\n",
    "                    continue\n",
    "                state[0].pop(0)\n",
    "                state[1] = ptr + 1\n",
    "    \n",
    "    def testInput(self):\n",
    "        # self.grammar = {'S': [['NP', 'VP']], 'NP': [['DT', 'N'], ['N']], 'VP': [['V'], ['V', 'ADV']]}\n",
    "        # self.nonTerminals = ['S', 'NP', 'VP']\n",
    "        # self.terminals = ['DT', 'N', 'ADV', 'V']\n",
    "        # sentence = \"People laugh\"\n",
    "        # lexicons = {\n",
    "        #     \"People\": [\"N\", \"V\"],\n",
    "        #     \"laugh\": [\"N\"],\n",
    "        # }\n",
    "\n",
    "        # self.grammar = {'S': [['NP', 'VP']], 'NP': [['ART', 'N'], ['ART', 'ADJ', 'N']], 'VP': [['V'], ['V', 'NP']]}\n",
    "        # self.nonTerminals = ['S', 'NP', 'VP']\n",
    "        # self.terminals = ['ART', 'N', 'ADJ', 'V']\n",
    "        # sentence = \"The dogs cried\"\n",
    "        # lexicons = {\n",
    "        #     \"The\": [\"ART\"],\n",
    "        #     \"dogs\": [\"N\", \"V\"],\n",
    "        #     \"cried\": [\"V\"],\n",
    "        # }\n",
    "\n",
    "        self.grammar = {'S': [['NP', 'VP']], 'NP': [['ART', 'N'], ['ART', 'ADJ', 'N']], 'VP': [['V'], ['V', 'NP']]}\n",
    "        self.nonTerminals = ['S', 'NP', 'VP']\n",
    "        self.terminals = ['ART', 'N', 'ADJ', 'V']\n",
    "        sentence = \"The old man cried\"\n",
    "        lexicons = {\n",
    "            \"The\": [\"ART\"],\n",
    "            \"old\": [\"ADJ\", \"N\"],\n",
    "            \"man\": [\"N\", \"V\"],\n",
    "            \"cried\": [\"V\"],\n",
    "        }\n",
    "        \n",
    "        self.printGrammar()\n",
    "        print()\n",
    "        self.parse(sentence, lexicons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Terminals: S NP VP\n",
      "Terminals: ART N ADJ V\n",
      "S -> NP VP\n",
      "NP -> ART N\n",
      "NP -> ART ADJ N\n",
      "VP -> V\n",
      "VP -> V NP\n",
      "\n",
      "Step:  1\n",
      "State:  [['S'], 0]\n",
      "Backup:  []\n",
      "\n",
      "Step:  2\n",
      "State:  [['NP', 'VP'], 0]\n",
      "Backup:  []\n",
      "\n",
      "Step:  3\n",
      "State:  [['ART', 'N', 'VP'], 0]\n",
      "Backup:  [[['ART', 'ADJ', 'N', 'VP'], 0]]\n",
      "\n",
      "Step:  4\n",
      "State:  [['N', 'VP'], 1]\n",
      "Backup:  [[['ART', 'ADJ', 'N', 'VP'], 0]]\n",
      "\n",
      "Step:  5\n",
      "State:  [['VP'], 2]\n",
      "Backup:  [[['ART', 'ADJ', 'N', 'VP'], 0]]\n",
      "\n",
      "Step:  6\n",
      "State:  [['V'], 2]\n",
      "Backup:  [[['ART', 'ADJ', 'N', 'VP'], 0], [['V', 'NP'], 2]]\n",
      "\n",
      "Step:  7\n",
      "State:  [['ART', 'ADJ', 'N', 'VP'], 0]\n",
      "Backup:  [[['V', 'NP'], 2]]\n",
      "\n",
      "Step:  8\n",
      "State:  [['ADJ', 'N', 'VP'], 1]\n",
      "Backup:  [[['V', 'NP'], 2]]\n",
      "\n",
      "Step:  9\n",
      "State:  [['N', 'VP'], 2]\n",
      "Backup:  [[['V', 'NP'], 2]]\n",
      "\n",
      "Step:  10\n",
      "State:  [['VP'], 3]\n",
      "Backup:  [[['V', 'NP'], 2]]\n",
      "\n",
      "Step:  11\n",
      "State:  [['V'], 3]\n",
      "Backup:  [[['V', 'NP'], 2], [['V', 'NP'], 3]]\n",
      "\n",
      "Parsing Done\n"
     ]
    }
   ],
   "source": [
    "parser = Parser()\n",
    "# parser.inputGrammar()\n",
    "# parser.printGrammar()\n",
    "parser.testInput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = input()\n",
    "# lexicons = {}\n",
    "# for tok in sentence.split():\n",
    "#     lexicons[tok] = input().split()\n",
    "# parser.parse(sentence, lexicons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
